# ethereum-optimism/specs Daily Update (Jun 23, 2025)
## OVERVIEW 
The day's activity focused on ongoing discussions for existing issues, particularly around optimizing `op-batcher` memory consumption, refining `op-node` interop modes, and streamlining contract assertions.

## KEY TECHNICAL DEVELOPMENTS
No new features, bug fixes, code refactoring, documentation enhancements, or tests were added.

## NEWLY OPENED PULL REQUESTS
No new pull requests were opened.

## CLOSED ISSUES
No issues were closed.

## NEW ISSUES
### Batcher Memory Optimization
A new issue, [#16537](https://github.com/ethereum-optimism/specs/issues/16537), was opened to spike memory consumption optimization in the `op-batcher`, particularly during L1 congestion.

## ACTIVE ISSUES
### Contract Assertion Refinement
Discussion continued on [#16362](https://github.com/ethereum-optimism/specs/issues/16362) regarding the removal of redundant assertions outside the `StandardValidator`. AmadiMichael outlined a two-phase plan: first, removing existing `ChainAssertions.sol` checks from `Deploy*.s.sol` scripts, and second, moving `ChainAssertions.sol` checks to the `StandardValidator`, potentially using a child contract if codesize limits are exceeded.

### Op-Node Trivial Interop Mode
Discussion on [#16519](https://github.com/ethereum-optimism/specs/issues/16519) centered on maintaining `op-node` functionality without a supervisor in trivial interop cases (single dependency set). Sebastianst clarified that this is to prevent churn for chain operations that only have a trivial dependency set, suggesting that a better `op-supervisor` + `op-node` implementation should be in place by the time interop merging is fully implemented.

### Op-Batcher Memory Optimization Spike
The newly opened issue [#16537](https://github.com/ethereum-optimism/specs/issues/16537) saw initial comments. Sebastianst suggested running a memory profiler. Geoknee provided a detailed recipe for using `pprof` to identify memory usage, concluding that the compressor is the primary source of memory consumption when the batcher's channel backlog grows. Geoknee also proposed two optimizations: making the shadow compressor use half the memory and more eagerly discarding the compressor after channel submission.